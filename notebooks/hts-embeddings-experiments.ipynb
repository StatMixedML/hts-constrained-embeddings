{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import (\n",
    "    preprocess_tourism_data,\n",
    "    split, \n",
    "    build_datasets, \n",
    "    get_bucket_samplers\n",
    ")\n",
    "\n",
    "HORIZON = 12\n",
    "\n",
    "# prepare data, create mappings of hierarchy that will be used for fitting/evaluation\n",
    "data, hierarchy_agg_dict, hierarchy_level_dict = preprocess_tourism_data('/root/data/raw/TourismData_v3.csv')\n",
    "\n",
    "# create train/val/test datasets\n",
    "splits = split(data.values, horizon = HORIZON, min_train_size = 108, max_train_size = 108)\n",
    "\n",
    "#train_datasets = build_datasets(data, splits, freq = freq)\n",
    "test_datasets = build_datasets(data, splits, val = False)\n",
    "samplers = get_bucket_samplers([train_data for (train_data, test_data) in test_datasets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.model import fit_deepar\n",
    "\n",
    "EPOCHS=10\n",
    "\n",
    "# fit DeepAR models with no embedding aggregation penalty\n",
    "fit_models_cat_var = [\n",
    "   fit_deepar(\n",
    "        training_data, \n",
    "        pred_length = HORIZON,\n",
    "        epochs=EPOCHS,\n",
    "        use_cat_var = True,\n",
    "        cardinality = [len(training_data)],\n",
    "        sampler = sampler,\n",
    "        hierarchy_agg_dict = hierarchy_agg_dict,\n",
    "        print_rec_penalty = False\n",
    "    ) \n",
    "    for (training_data, _), sampler in zip(test_datasets, samplers)\n",
    "]\n",
    "\n",
    "# fit DeepAR models with embedding aggregation penalty\n",
    "fit_models_embed_agg = [\n",
    "    fit_deepar(\n",
    "        training_data,\n",
    "        pred_length = HORIZON,\n",
    "        epochs=EPOCHS,\n",
    "        use_cat_var = True,\n",
    "        cardinality = [len(training_data)],\n",
    "        sampler = sampler,\n",
    "        hierarchy_agg_dict = hierarchy_agg_dict,\n",
    "        embedding_agg_penalty = 1,\n",
    "        print_rec_penalty = False\n",
    "    ) \n",
    "    for (training_data, _), sampler in zip(test_datasets, samplers)\n",
    "]\n",
    "\n",
    "# fit DeepAR models with self-supervised penalty\n",
    "fit_models_self_sup = [\n",
    "    fit_deepar(\n",
    "        training_data, \n",
    "        pred_length = HORIZON,\n",
    "        epochs=EPOCHS,\n",
    "        use_cat_var = True,\n",
    "        cardinality = [len(training_data)],\n",
    "        sampler = sampler,\n",
    "        hierarchy_agg_dict = hierarchy_agg_dict,\n",
    "        self_supervised_penalty = 10e-8,\n",
    "        print_rec_penalty = False\n",
    "    ) \n",
    "    for (training_data, _), sampler in zip(test_datasets, samplers)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from src.model import unserialize_all\n",
    "from src.evaluation import evaluate_optimal_rec, evaluate_deepar\n",
    "\n",
    "# baseline DeepAR w/ embedding\n",
    "filenames_cat_var = [f'/root/data/test_preds/test_model_cat_var_fold_{i}_preds.csv' for i in range(len(test_datasets))]\n",
    "evaluations_cat_var = [\n",
    "    evaluate_deepar(predictor, train_data, test_data, hierarchy_level_dict, filename) \n",
    "    for (predictor, _),  (train_data, test_data), filename in zip(fit_models_cat_var, test_datasets, filenames_cat_var)\n",
    "]\n",
    "\n",
    "# embedding aggregation penalty\n",
    "filenames_embed_agg = [f'/root/data/test_preds/test_model_embed_agg_fold_{i}_preds.csv' for i in range(len(test_datasets))]\n",
    "evaluations_embed_agg = [\n",
    "    evaluate_deepar(predictor, train_data, test_data, hierarchy_level_dict, filename) \n",
    "    for (predictor, _), (train_data, test_data), filename in zip(fit_models_embed_agg, test_datasets, filenames_embed_agg)\n",
    "]\n",
    "\n",
    "# self-supervised penalty\n",
    "evaluations_self_sup = [\n",
    "    evaluate_deepar(predictor, train_data, test_data, hierarchy_level_dict) \n",
    "    for (predictor, _), (train_data, test_data) in zip(fit_models_self_sup, test_datasets)\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconcile Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconciled_preds = [pd.read_csv(f) for f in glob(f'/root/data/test_reconciled_preds/test_model_cat_var*')]\n",
    "evaluations_mint_model = [\n",
    "    evaluate_optimal_rec(preds, test_data, hierarchy_level_dict) \n",
    "    for preds, (_, test_data) in zip(reconciled_preds, test_datasets)\n",
    "]\n",
    "reconciled_preds = [pd.read_csv(f) for f in glob(f'/root/data/test_reconciled_preds/test_model_embed_agg*')]\n",
    "evaluations_mint_embed_agg = [\n",
    "    evaluate_optimal_rec(preds, test_data, hierarchy_level_dict) \n",
    "    for preds, (_, test_data) in zip(reconciled_preds, test_datasets)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation import agg_evaluations, compare_performance\n",
    "\n",
    "baseline = agg_evaluations(evaluations_cat_var)\n",
    "embedd_agg = agg_evaluations(evaluations_embed_agg)\n",
    "reconciled = agg_evaluations(evaluations_mint_model)\n",
    "reconciled_embedd_agg = agg_evaluations(evaluations_mint_embed_agg)\n",
    "\n",
    "compare_performance(\n",
    "    [\n",
    "        baseline, \n",
    "        embedd_agg, \n",
    "        reconciled, \n",
    "        reconciled_embedd_agg, \n",
    "    ],\n",
    "    model_names = [\n",
    "        'DeepAR',\n",
    "        'DeepAR-Embed-Agg',\n",
    "        'DeepAR-MinT',\n",
    "        'DeepAR-Embed-Agg-MinT',\n",
    "    ],\n",
    "    levels = ['all', 'country', 'region-by-travel']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}